
---

## 1ï¸âƒ£ Problem Statement (Before Kafka)

Example: **Medium.com like system**

When a blog is published, we need to:

- âœ… Save blog in main database
    
- âœ… Index blog in **Elasticsearch** (for search)
    
- âœ… Increase **userâ€™s blog count**
    

ðŸ‘‰ These are **multiple independent actions** triggered by **one event (blog published)**.

---

## 2ï¸âƒ£ Approach 1: One Queue, One Consumer Doing Everything

### Flow

- API publishes message to RabbitMQ
    
- Consumer:
    
    - Updates count in DB
        
    - Indexes data in Elasticsearch
        

### Diagram 

```mermaid
flowchart LR
    User --> API
    API --> RabbitMQ
    RabbitMQ --> Consumer
    Consumer -->|count++| MainDB
    Consumer -->|index| ElasticSearch
```

### âŒ Problem

What if:

- DB update succeeds
    
- Elasticsearch indexing fails
    

Result:

- Blog count is correct âŒ
    
- Search does not show blog âŒ
    

ðŸ‘‰ **System becomes inconsistent**

---

## 3ï¸âƒ£ Approach 2: Two Queues, Two Consumers

Idea:

- One queue for search
    
- One queue for counter
    

### Flow

- API writes **same event** to two RabbitMQ queues
    
- Each queue has its own consumer
    

### Diagram

```mermaid
flowchart LR
    User --> API
    API --> RabbitMQ_Search
    API --> RabbitMQ_Counter

    RabbitMQ_Search --> SearchConsumer --> ElasticSearch
    RabbitMQ_Counter --> CounterConsumer --> MainDB
```

### âŒ Problem Still Exists

What if:

- API writes successfully to Search queue
    
- API fails while writing to Counter queue
    

Result:

- Blog is searchable âœ…
    
- Blog count is wrong âŒ
    

ðŸ‘‰ **Still inconsistent**

---

## 4ï¸âƒ£ Root Cause of the Problem

The real problem is:

> âŒ **Writing the same event multiple times**

We want:

- **Write once**
    
- **Read by many services independently**
    

This is exactly where **Message Streams** come in.

---

## 5ï¸âƒ£ Message Streams â€“ Core Idea

### Key Concept

> **Write once, read by many**

- Producer writes **one event**
    
- Multiple consumers read **the same event**
    
- Consumers are **independent**
    
- Failure of one consumer does **not affect others**
    

---

## 6ï¸âƒ£ Kafka Solution (Approach 3)

Kafka is a **message stream platform**.

### Flow

- API publishes one message to Kafka
    
- Search service consumes it
    
- Counter service consumes it
    

### Diagram

```mermaid
flowchart LR
    User --> API
    API --> KafkaTopic

    KafkaTopic --> SearchService --> ElasticSearch
    KafkaTopic --> CounterService --> MainDB
```

### âœ… Why This Works

- API writes **only once**
    
- Search and Counter read **independently**
    
- If Search fails:
    
    - Counter still works
        
- If Counter fails:
    
    - Search still works
        
- Failed consumer can **re-read messages**
    

ðŸ‘‰ **Eventually consistent system (industry standard)**

---

## 7ï¸âƒ£ Message Queue vs Message Stream

### Message Queue (RabbitMQ, SQS)

- One message â†’ consumed by **one consumer**
    
- Message is **removed after consumption**
    
- Used for **task processing**
    

```mermaid
flowchart LR
    Queue --> Consumer1
    Queue --> Consumer2
    Queue --> Consumer3
```

ðŸ‘‰ Each message goes to **only one consumer**

---

### Message Stream (Kafka, Kinesis)

- One message â†’ consumed by **many consumer groups**
    
- Message is **not deleted immediately**
    
- Used for **event-driven systems**
    

```mermaid
flowchart LR
    Stream --> SearchService
    Stream --> CounterService
```

ðŸ‘‰ **Same message is read multiple times**

---

## 8ï¸âƒ£ Kafka Internals (Very Important)

### Kafka Basics

- Kafka stores data in **Topics**
    
- Each topic has **Partitions**
    
- Producer sends message to a **topic**
    
- Message goes to a **partition** (based on key)
    

### Diagram

```mermaid
flowchart LR
    Producer --> Topic
    Topic --> Partition1
    Topic --> Partition2
    Topic --> Partition3
```

---

### Ordering Guarantee

- âœ… Messages are **ordered inside one partition**
    
- âŒ No ordering guarantee **across partitions**
    

ðŸ‘‰ If ordering matters, use **same key**

---

## 9ï¸âƒ£ Kafka Consumer Limitation

### Rule

> **Number of consumers â‰¤ number of partitions**

Example:

- Partitions = 3
    
- Consumers = 5
    

Result:

- 2 consumers will be **idle**
    

### Diagram

```mermaid
flowchart LR
    Partition1 --> Consumer1
    Partition2 --> Consumer2
    Partition3 --> Consumer3

    Consumer4:::idle
    Consumer5:::idle

    classDef idle fill:#fdd,stroke:#f00
```

ðŸ‘‰ For scaling consumers, **increase partitions**

---



