
---

# ğŸ›  Step 1: Namespace

Create a namespace called `dev`

```yaml
# namespace-dev.yml
apiVersion: v1
kind: Namespace
metadata:
  name: dev
```

Apply it:

```bash
kubectl apply -f namespace-dev.yml
kubectl get namespaces
```

ğŸ‘‰ Check if `dev` shows up.

---

# ğŸ›  Step 2: Pod with labels

Create a Pod (one small team) inside `dev`, add a **label**.

```yaml
# pod-nginx.yml
apiVersion: v1
kind: Pod
metadata:
  name: myapp
  namespace: dev
  labels:
    app: myapp
    tier: frontend
spec:
  containers:
    - name: nginx
      image: nginx:latest
      ports:
        - containerPort: 80
```

Apply:

```bash
kubectl apply -f pod-nginx.yml
kubectl get pods -n dev --show-labels
```

ğŸ‘‰ Notice labels like `app=myapp,tier=frontend`.

---

# ğŸ›  Step 3: ReplicaSet

Now letâ€™s say you want **3 copies of this Pod**.

```yaml
# replicaset-nginx.yml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: myapp-rs
  namespace: dev
spec:
  replicas: 3
  selector:
    matchLabels:
      app: myapp
  template:
    metadata:
      labels:
        app: myapp
    spec:
      containers:
        - name: nginx
          image: nginx:latest
          ports:
            - containerPort: 80
```

Apply:

```bash
kubectl apply -f replicaset-nginx.yml
kubectl get pods -n dev
```

ğŸ‘‰ You should see **3 pods** created.

---

# ğŸ›  Step 4: Deployment

Now we add a manager (Deployment) to control ReplicaSets. For Rollback and updates. For new updated first run new pods and then stop existing running pods.

```yaml
# deployment-nginx.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: myapp-deploy
  namespace: dev
spec:
  replicas: 2
  selector:
    matchLabels:
      app: myapp-deploy
  template:
    metadata:
      labels:
        app: myapp-deploy
    spec:
      containers:
        - name: nginx
          image: nginx:1.21
          ports:
            - containerPort: 80
```

Apply:

```bash
kubectl apply -f deployment-nginx.yml
kubectl get deployments -n dev
kubectl get pods -n dev
kubectl set image deployment/myapp-deployment nginx=nginx:1.22 -n dev
```

ğŸ‘‰ Youâ€™ll see 2 pods running under this Deployment.  
ğŸ‘‰ If you update `nginx:1.22` and re-apply, Deployment will **roll out** new pods safely.

---

# ğŸ›  Step 5: StatefulSet (optional but good practice)

For apps that need fixed identity (like DB).

```yaml
# statefulset-mysql.yml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: mysql
  namespace: dev
spec:
  serviceName: "mysql"
  replicas: 2
  selector:
    matchLabels:
      app: mysql
  template:
    metadata:
      labels:
        app: mysql
    spec:
      containers:
        - name: mysql
          image: mysql:5.7
          ports:
            - containerPort: 3306
```

Apply:

```bash
kubectl apply -f statefulset-mysql.yml
kubectl get pods -n dev
```

ğŸ‘‰ Pod names will be `mysql-0`, `mysql-1` (stable identities).

---

# ğŸ›  Step 6: Clean up

```bash
kubectl delete namespace dev
```

(Removes all resources inside `dev`.)

---

## ğŸ” What is a Selector in Kubernetes?

- **Labels** = tags on Pods.
    
- **Selector** = filter rule that matches those tags.
    

ğŸ‘‰ Think:

- Every employee (Pod) wears a **badge** (`role=engineer`, `team=backend`).
    
- HR (ReplicaSet / Deployment / Service) says:
    
    - _â€œI only manage employees with badge `role=engineer`.â€_
        

Thatâ€™s the **selector**.

---

## âš™ï¸ Example: Pod with label

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: myapp
  namespace: dev
  labels:
    app: myapp
    tier: frontend
spec:
  containers:
    - name: nginx
      image: nginx:latest
```

This Pod has labels:

- `app=myapp`
    
- `tier=frontend`
    

---

## âš™ï¸ Example: ReplicaSet with selector

```yaml
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: myapp-rs
  namespace: dev
spec:
  replicas: 3
  selector:                # selector = which Pods I control
    matchLabels:
      app: myapp           # must match Pod's label
  template:                # blueprint for new Pods
    metadata:
      labels:
        app: myapp
    spec:
      containers:
        - name: nginx
          image: nginx:latest
```

ğŸ‘‰ What happens here?

1. Selector says: _â€œI will only manage pods with `app=myapp`.â€_
    
2. The template creates **new pods** with that label.
    
3. ReplicaSet keeps exactly `3` of them alive.

4. If existing pod with same name is already running then it consider it and doesnt manage 
that pod (Did practical)
---

## âš™ï¸ Why is Selector important?

- If labels donâ€™t match the selector â†’ ReplicaSet/Deployment wonâ€™t manage those pods.
    
- Services also use selectors to decide **where to send traffic**.
    

Example Service:

```yaml
apiVersion: v1
kind: Service
metadata:
  name: myapp-service
  namespace: dev
spec:
  selector:
    app: myapp    # send traffic to pods with app=myapp
  ports:
    - port: 80
      targetPort: 80
```

ğŸ‘‰ Only Pods with label `app=myapp` will receive traffic from this Service.

---

# 1ï¸âƒ£ What goes into **one Pod**?

ğŸ‘‰ **Rule of thumb**:

- A **Pod = tightly coupled containers** that must always live/die together.
    
- If they are **independent services**, they should be in **separate Pods**.
    

### âœ… Good use cases (multiple containers in one Pod):

- **Main app + helper (sidecar)**
    
    - Example: Spring Boot app + log shipper (sidecar for pushing logs).
        
- **Reverse proxy + app** that always go together.
    
- **Data scraper + tiny cache container** that only works for that scraper.
    

### âŒ Bad use case:

- Frontend + Backend in same pod â†’ Wrong, because they donâ€™t need to scale together.
    
- MySQL + Redis in same pod â†’ Wrong, because theyâ€™re different systems with different lifecycles.
    

ğŸ‘‰ So **Spring Boot and React** = **two separate Pods**.

---

# 2ï¸âƒ£ What goes into **one Namespace**?

ğŸ‘‰ **Namespace = logical boundary (department)**.  
Itâ€™s about **organization, access control, and resource limits**, not tight coupling.

### Common patterns:

- **By environment**:
    
    - `dev`, `test`, `prod` â†’ each environment gets its own namespace.
        
- **By team**:
    
    - `frontend-team`, `backend-team` â†’ each team manages their own namespace.
        
- **By application (less common)**:
    
    - `lms-system`, `inventory-system` if they are totally different products.
        

### Example with your app:

- You create a namespace `dev`.
    
- Inside it:
    
    - `frontend-deployment` (pods running React app)
        
    - `backend-deployment` (pods running Spring Boot app)
        
    - `database-statefulset` (pods running PostgreSQL or MySQL)
        

All belong to the same **namespace (dev)** because they are part of the **same project/environment**.

---

âœ… For your Spring Boot + React system:

- **Pods** â†’ one for frontend, one for backend, one for DB.
    
- **Namespace** â†’ all in `dev` (if youâ€™re learning). Later youâ€™ll have `prod`, `qa`, etc.
    

---
# Sidecar : 
---

## ğŸš— Real-world analogy

Think of a **motorbike with a sidecar**:

- The **motorbike** = main container (your app).
    
- The **sidecar** = small helper container that always rides along, providing extra functionality.
    

They **travel together**, but the sidecar isnâ€™t the star â€” it just supports the main vehicle.

---

## ğŸ’» In Kubernetes

A **sidecar container** is a **secondary container inside the same Pod** that supports the main container.

ğŸ‘‰ They share:

- The **same network** (so they can talk via `localhost`)
    
- The **same storage volumes**
    

---

## âš™ï¸ Examples of Sidecar Pattern

1. **Logging sidecar**
    
    - Main container: Spring Boot app.
        
    - Sidecar: log shipper (e.g., Fluentd) that forwards logs to Elasticsearch.
        
2. **Proxy sidecar**
    
    - Main container: App.
        
    - Sidecar: Envoy proxy (used in service mesh like Istio) to handle traffic/security.
        
3. **File updater sidecar**
    
    - Main container: Nginx serving React frontend.
        
    - Sidecar: Container that updates React build files periodically.
        

---

## ğŸ“ Example YAML (Spring Boot + log sidecar)

```yaml
apiVersion: v1
kind: Pod
metadata:
  name: springboot-with-logger
spec:
  containers:
    - name: springboot
      image: my-springboot:latest
      ports:
        - containerPort: 8080
    - name: log-agent
      image: busybox
      command: ["sh", "-c", "tail -f /var/log/app.log"]
      volumeMounts:
        - name: log-volume
          mountPath: /var/log
  volumes:
    - name: log-volume
      emptyDir: {}
```

- `springboot` = main app writing logs to `/var/log/app.log`
    
- `log-agent` = sidecar reading logs and doing something (ship, process, forward)
    
- Both share the **log-volume**
    

---

## âœ… When to use Sidecar?

- If the helper must **always run with the main app**
    
- If they must **share same network/storage**
    
- If it doesnâ€™t make sense to scale them separately
    

---

ğŸ‘‰ So, **sidecar = helper container** in the same Pod.

---
