
---

## What is Kafka ? 

Kafka is a tool used for managing and moving data between different parts of a system, especially <font color="#ffff00">when those parts need to communicate quickly and handle a lot of information.</font>

Open-source distributed (multiple server) event (data) streaming platform.

### **Problem Kafka Solves:**

Imagine a social media app where users can like posts, and the app needs to notify the post's owner when someone likes their post. The traditional approach would involve directly updating the database and sending a notification every time a like happens. But this can become a problem when there are millions of users and likes happening at the same time. It could overwhelm the database, slow down the app, and cause notifications to be delayed.

 <font color="#ffff00">Executing an API</font> call is typically a <font color="#ffff00">synchronous task,</font> meaning that the caller has to wait for the API to finish its work and send back a response before it can continue. This waiting can take time, especially if the API is doing something complex.

Kafka, on the other hand, provides <font color="#ffff00">asynchronous operations.</font> This means that when a system sends a message to Kafka, it doesn't have to wait for a response. Kafka takes care of delivering the message to the right place, allowing the system to continue working without delay. This makes Kafka very useful for scenarios where you don't want to wait around for something to finish, like processing large amounts of data or handling real-time events.

### **How Kafka Helps:**

Kafka acts like a middleman (or a "broker") that handles all these messages (like "User A liked Post B") efficiently. Hereâ€™s how it works in simple terms:

1. **Producers**: These are the parts of your app that create messages. For example, when a user likes a post, the app creates a message saying, "User A liked Post B" and sends it to Kafka.

2. **Kafka Topics**: Kafka stores these messages in something called "topics." Think of a topic as a specific category or channel where all similar messages are grouped together. In this case, you might have a topic called "post-likes."

3. **Consumers**: These are parts of your app that read and process these messages. For example, a notification service can consume messages from the "post-likes" topic to send a notification to the post's owner.

### **Real-World Example: Social Media Likes and Notifications**

- **When a user likes a post**: 
   - The app (Producer) sends a message to the "post-likes" topic in Kafka.
- **Kafka stores this message**:
   - The message sits in the "post-likes" topic, ready for any service that needs it.
- **Notification service (Consumer)**:
   - This service reads the message from the "post-likes" topic and sends a notification to the post's owner.

### **Benefits:**
- **Scalability**: Kafka can handle a massive number of messages, so even if millions of users are liking posts at the same time, it wonâ€™t slow down.
- **Decoupling**: The services that produce and consume messages are independent. The app creating likes doesnâ€™t need to know how the notification is sent.
- **Reliability**: Messages are stored in Kafka until they are processed, ensuring that no notifications are missed.


---

 Basic Kafka terminologies :

1. **Producer**:  
   A producer is like a messenger that sends messages (or data) to Kafka. For example, if you have a service that generates data (like user activity on a website), it acts as a producer by sending that data to Kafka.

2. **Consumer**:  
   A consumer is the receiver that takes messages from Kafka. For example, if you have another service that processes or stores the data generated by users, it acts as a consumer by reading those messages from Kafka.

3. **Topic**:  
   A topic is like a channel or category where messages are sent. Producers send messages to a specific topic, and consumers read messages from that topic. For example, you could have a "user-activity" topic for all messages related to user actions.

4. **Partition**:  
   A topic can be split into smaller parts called partitions. This helps Kafka handle large amounts of data efficiently. Each partition can be thought of as a separate sequence of messages within a topic, allowing Kafka to distribute the workload across multiple servers.

5. **Broker**:  
   A broker is a server in a Kafka cluster (a group of connected Kafka servers). The broker's job is to manage topics, store messages, and handle communication between producers and consumers.

6. **Cluster**:  
   A cluster is a group of Kafka brokers working together. If one broker fails, the cluster can still function, making Kafka reliable and scalable.

7. **ZooKeeper**:  
   ZooKeeper is a tool that helps manage the Kafka cluster. It keeps track of the brokers, topics, and partitions, ensuring everything runs smoothly. However, newer versions of Kafka are moving away from using ZooKeeper.

8. **Offset**:  
   An offset is a unique number that identifies each message within a partition. Consumers use offsets to keep track of which messages they've read, so they don't process the same message twice.

9. **Consumer Group**:  
   A consumer group is a group of consumers that work together to read messages from a topic. Each consumer in the group reads from different partitions of the topic, allowing them to share the workload.


----

Here are the commands exactly as you provided:

### ðŸŸ¢ INSTALLATION COMMANDS

```bash
zookeeper-server-start.bat ..\..\config\zookeeper.properties
```

```bash
kafka-server-start.bat ..\..\config\server.properties
```

```bash
kafka-topics.bat --create --topic my-topic --bootstrap-server localhost:9092 --replication-factor 1 --partitions 3
```

```bash
kafka-console-producer.bat --broker-list localhost:9092 --topic my-topic
```

```bash
kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic my-topic --from-beginning
```

### ðŸŸ¢ SENDING MESSAGES COMMANDS

```bash
zookeeper-server-start.bat ..\..\config\zookeeper.properties
```

```bash
kafka-server-start.bat ..\..\config\server.properties
```

```bash
kafka-topics.bat --create --topic foods --bootstrap-server localhost:9092 --replication-factor 1 --partitions 4
```

```bash
kafka-console-producer.bat --broker-list localhost:9092 --topic foods --property "key.separator=-" --property "parse.key=true"
```

```bash
kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic foods --from-beginning --property "key.separator=-" --property "print.key=false"
```


----


### **Topic**
- **Definition**: A topic is a named container that holds similar types of events or messages. Its unique identifier is its name.
- **Example**: A "Student" topic might contain all student-related data, while an "Order" topic could hold order-related data.
- **Analogy**: Think of a topic like a table in a database, where each table stores related information.
- **Location**: Topics reside within a Kafka broker (server).
- **Message Flow**:
  - **Producer**: The producer sends messages to a topic, which are then stored in partitions (either in a round-robin manner across partitions or directly into specific partitions).
  - **Consumer**: The consumer continuously polls the topic for new messages using the topic name.

### **Partition**
- **Definition**: A topic is divided into multiple parts called partitions. This allows Kafka to distribute data across multiple brokers, making the system scalable and fault-tolerant.
- **Replication Factor**: Each partition can be copied (replicated) to other brokers based on a replication factor. This ensures fault toleranceâ€”if one broker fails, the data is still available on another.
- **Partition Structure**:
  - **Location of Messages**: The actual messages are stored within partitions.
  - **Number of Partitions**: When creating a topic, you specify the number of partitions. This number can be adjusted later.
  - **Order within Partitions**: Each partition is an ordered, immutable sequence of records. This means that messages within a partition are stored in the exact order they were produced.
  - **Offset**: Each message in a partition has a unique identifier called an offset, which is an incremental number. This offset helps in tracking the order of messages.
  - **Growth**: As new records are produced, the partition grows, and the offset increases.

---

We can send  data through Producer to consumer as key-value pair or only value .

### 1. **With Key:**
- **Partitioning**: When you send a message with a key, Kafka uses the key to determine which partition the message will go to. The key is hashed, and this hash value determines the partition.
- **Order within Partition**: Kafka preserves the order of messages **within** a partition. This means that if you send multiple messages with the same key, they will all go to the same partition and be consumed in the order they were produced.
- **Order across Partitions**: However, if messages with different keys are sent to different partitions, the order between partitions is not guaranteed. The consumer will read from multiple partitions, and the overall order of messages may seem mixed.

### 2. **Without Key:**
- **Round-robin Partitioning**: If you send a message without a key, Kafka typically distributes messages across partitions in a round-robin fashion. This means that consecutive messages may end up in different partitions.
- **Order within Partition**: As with keyed messages, order is still preserved within each partition.
- **Order across Partitions**: Since messages are spread across partitions, the order between partitions is not guaranteed.

### Key Points:
- **Order Guarantee**: Kafka guarantees message order **within a single partition**. If you need to preserve the order of all messages, you should either:
  - Use a single partition (which limits scalability), or
  - Ensure that all related messages (which need to be in order) use the same key so that they all go to the same partition.

- **No Global Order**: When you have multiple partitions, Kafka does not guarantee a global order across all partitions, regardless of whether you use a key or not.

---


**Consumer Offset:**
- The consumer offset is a marker that keeps track of the last message read by a consumer in a Kafka topic. Each consumer group maintains its own offset for every partition it reads from.
  
- **`_consumer_offset` Topic:**
  - Kafka has a special internal topic named `_consumer_offset` that stores the latest offsets for each partition of every consumer group.
  - This topic is not meant to be directly modified by clients. Instead, Kafka automatically updates it to reflect the current offset of each consumer.
  - This helps Kafka ensure that messages are not lost or duplicated.

- **Consumer Groups:**
  - For each consumer group, Kafka creates a separate entry in the `_consumer_offset` topic to store the offsets.
  - For example, if you have two consumer groups, each with four consumers, Kafka will maintain entries in the `_consumer_offset` topic for each consumer's offset.

- **Partition Assignment:**
  - When a consumer joins a group, it sends a request to the group coordinator.
  - The group coordinator assigns partitions to the consumer based on the number of consumers and the current assignments.
  - Kafka tries to keep the same partitions assigned to the same consumers ("sticky" assignment) to allow consumers to continue processing from where they left off, even after rebalancing.

-  When we run consumer without group id every id kafka create and assign new group id to it.
-  Assign producer to partitions in round-robin fashion.

Here are the commands to describe a topic, list all available consumer groups, and list all topics in Kafka:

### **Describe a Topic**
To describe a specific topic, use the following command:

```bash
kafka-topics.bat --describe --topic <topic_name> --bootstrap-server localhost:9092
```

Replace `<topic_name>` with the name of the topic you want to describe. For example, to describe the topic `my-topic`, the command would be:

```bash
kafka-topics.bat --describe --topic my-topic --bootstrap-server localhost:9092
```

### **List All Available Consumer Groups**
To list all consumer groups in Kafka, use the following command:

```bash
kafka-consumer-groups.bat --list --bootstrap-server localhost:9092
```

### **List All Topics**
To list all topics in Kafka, use the following command:

```bash
kafka-topics.bat --list --bootstrap-server localhost:9092
```



To create a consumer and assign a group ID in Kafka, you can use the following command:

### **Creating a Consumer with a Specific Group ID**

```bash
kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic <topic_name> --group <group_id>
```

Replace `<topic_name>` with the name of the topic you want to consume from, and replace `<group_id>` with the desired group ID.

For example, if you want to consume from the topic `my-topic` with the group ID `my-group`, the command would be:

```bash
kafka-console-consumer.bat --bootstrap-server localhost:9092 --topic my-topic --group my-group
```

This command will create a consumer in the specified consumer group (`my-group`) and start consuming messages from the specified topic (`my-topic`).




### Kafka Segments, Commit Logs, and Retention Policy

#### 1. **Segments**
- **Definition**: 
  - In Kafka, a segment is a smaller part of a topic's partition log. Each partition in Kafka is broken down into multiple segments, and these segments are stored as individual files on disk.
- **Purpose**: 
  - Segments help manage the partition logs efficiently, making it easier to handle large volumes of data by dividing the log into manageable chunks.
- **Segment Naming**: 
  - Each segment file is named using the offset of the first message it contains, which helps in organizing and retrieving the logs.

#### 2. **Commit Logs**
- **Definition**: 
  - A commit log in Kafka is a log of all messages that have been produced to a partition. It is an append-only, immutable log where each message is assigned a unique offset.
- **Purpose**: 
  - The commit log ensures that all messages are stored reliably and can be consumed by consumers in order. This log is what makes Kafka a highly durable and fault-tolerant system.
- **Location**: 
  - Commit logs (or partition logs) are stored on disk in a directory specified by the `log.dirs` configuration in Kafka's server properties file.

#### 3. **Retention Policy**
- **Definition**: 
  - The retention policy in Kafka determines how long Kafka retains messages in a topic before deleting them. 
- **Types of Retention Policies**:
  - **Time-Based Retention**: Messages are retained for a specified period (e.g., 7 days). After this period, the messages are eligible for deletion.
  - **Size-Based Retention**: Messages are retained until the total log size reaches a specified limit (e.g., 100GB). When the log size exceeds this limit, older segments are deleted to free up space.
  - **Log Compaction**: Instead of deleting old messages based on time or size, Kafka keeps the latest version of each key in the log. This is useful for scenarios where you only need the latest state of each record.
- **Configuration**: 
  - The retention policy is configured in Kafkaâ€™s server properties file using settings like `log.retention.hours` (time-based) or `log.retention.bytes` (size-based).


How to create  and run mutiple kafka broker ? 
Copy server.properties file and rename it (like server-1.properties) and change
id and server port.

